# Emotion Based Music Recommendation System

# ğŸµ RhythmiQ â€“Music Recommendation System

## ğŸ“Œ Overview

RhythmiQ is an emotion-based music recommendation system that uses facial expression recognition to detect a userâ€™s emotional state in real time and automatically play music that matches their mood. By combining Computer Vision and Deep Learning, the system delivers a personalized and emotionally intelligent music experience without requiring any manual input from the user.
The system captures live video through a webcam, detects the userâ€™s face using OpenCV, predicts emotions using a trained Convolutional Neural Network (CNN), and recommends music accordingly. This project demonstrates how AI can understand human emotions and enhance digital experiences through smart automation.

---
## ğŸ¯ Features

- Real-time facial emotion detection
- CNN-based emotion classification
- Automatic music recommendation
- Webcam-based interaction
- Emotion-aware personalized playlists

  
---

## ğŸ˜Š Emotions & Music Recommendation
- Happy ğŸ˜„ â€“ Upbeat and energetic tracks (Pop, Dance)
- Sad ğŸ˜¢ â€“ Calm, slow-tempo songs (Lo-fi, Acoustic)
- Angry ğŸ˜  â€“ Intense or expressive music (Rock, Metal)
- Surprised ğŸ˜² â€“ Dynamic or cinematic tracks
- Neutral ğŸ˜ â€“ Balanced or favorite playlists
- Fear ğŸ˜¨ â€“ Soothing and relaxing music
- Disgust ğŸ¤¢ â€“ Neutral music or track skip

  
---

## ğŸ› ï¸ Technologies Used
- Python
- OpenCV â€“ Face detection & image processing
- TensorFlow & Keras â€“ Deep learning & CNN model
- Scikit-learn â€“ Machine learning utilities
- NumPy & Pandas â€“ Data handling
- Matplotlib â€“ Data visualization
- Flask
- HTML/CSS

  
---
## Emotion-Based-Music-Recommendation-System/
- â”‚
- â”œâ”€â”€ app.py                      # Main Flask application
- â”œâ”€â”€ emotion.py                  # Emotion detection logic
- â”œâ”€â”€ facialemotionmodel.h5       # Trained CNN model for emotion recognition
- â”œâ”€â”€ requirements.txt            # Python dependencies
- â”œâ”€â”€ Procfile                    # Deployment configuration
- â”œâ”€â”€ setup.sh                    # Setup script for deployment
- â”œâ”€â”€ LICENSE                     # License file
- â”‚
- â”œâ”€â”€ data/
- â”‚   â”œâ”€â”€ filtered_track_df.csv   # Music dataset
- â”‚   â””â”€â”€ preprocess_data.ipynb   # Dataset preprocessing notebook
- â”‚
- â””â”€â”€ README.md

---

## âš™ï¸ Installation & Setup

1ï¸âƒ£ Clone the Repository
git clone https://github.com/Tannu265/Emotion-Based-Music-Recommendation-System.git
cd Emotion-Based-Music-Recommendation-System

2ï¸âƒ£ Create a Virtual Environment (Optional but Recommended)
python -m venv venv
source venv/bin/activate   # On Windows: venv\Scripts\activate

3ï¸âƒ£ Install Dependencies
pip install -r requirements.txt

4ï¸âƒ£ Run the Application
python app.py

---

## ğŸ“¸ How It Works
- The webcam captures the userâ€™s face.
- A CNN model predicts the userâ€™s emotion.
- The system filters songs related to that emotion.
- Music recommendations are displayed instantly.

---

# ğŸ“Š Dataset
- The music dataset (filtered_track_df.csv) contains tracks tagged with emotional attributes.
- Data preprocessing steps are documented in preprocess_data.ipynb.

---

## ğŸ“Œ Conclusion
RhythmiQ successfully integrates facial emotion recognition with automated music recommendation, creating a smart and emotionally responsive system. By leveraging AI, deep learning, and computer vision, the project demonstrates how technology can adapt to human emotions and provide a more personalized, empathetic, and engaging user experience.

---
## Author 
**Tannu Jha**
