# Emotion-Based-Music-Recommendation-System-
---
# ğŸµ FaceBeats â€“ Emotion-Based Music Recommendation System
---
# ğŸ“Œ Overview

FaceBeats is an intelligent emotion-based music recommendation system that uses facial expression recognition to detect a userâ€™s current emotional state and automatically play music that matches their mood.
By combining Computer Vision and Deep Learning, the system creates a personalized and emotionally intuitive music experience in real time.

Instead of manually choosing songs, users simply sit in front of a webcam, and FaceBeats takes care of the rest ğŸ§âœ¨
---

# ğŸ¯ Key Features

Real-time facial emotion detection using a webcam
Emotion classification using a Convolutional Neural Network (CNN)
Automatic music recommendation based on detected emotion
Smooth integration of OpenCV and TensorFlow/Keras
Supports multiple human emotions
---

# ğŸ˜Š Emotions Recognized & Music Behavior
Emotion	Facial Expression	Music Recommendation
Happy ğŸ˜„	Smile, relaxed eyes	Upbeat & energetic tracks (Pop, Dance)
Sad ğŸ˜¢	Droopy eyes, downturned mouth	Soft, slow-tempo songs (Lo-fi, Acoustic)
Angry ğŸ˜ 	Furrowed brows, clenched jaw	Intense or expressive music (Rock, Metal)
Surprised ğŸ˜²	Raised eyebrows, open mouth	Dynamic or cinematic tracks
Neutral ğŸ˜	No strong expression	Balanced or favorite playlists
Fear ğŸ˜¨	Wide eyes, tense face	Calm & soothing music
Disgust ğŸ¤¢	Wrinkled nose, curled lips	Neutral music or skip track
---
# ğŸ› ï¸ Tech Stack

Programming Language: Python
Computer Vision: OpenCV
Deep Learning: TensorFlow, Keras
Machine Learning: Scikit-learn
Data Handling: NumPy, Pandas
Visualization: Matplotlib
---

# ğŸ“‚ Project Structure
FaceBeats/
â”‚
â”œâ”€â”€ final_model.py              # Main application (webcam + music playback)
â”œâ”€â”€ emotion.py                  # Emotion prediction logic
â”œâ”€â”€ cnn.py                      # CNN model architecture
â”œâ”€â”€ train_CNN.py                # Training script for CNN
â”œâ”€â”€ load_and_process.py         # Dataset loading & preprocessing
â”œâ”€â”€ Machine_learning_models.ipynb # Model experiments & evaluation
â”œâ”€â”€ haarcascade_frontalface_default.xml # Face detection model
â”œâ”€â”€ Classifier.hdf5             # Trained emotion recognition model
â””â”€â”€ README.md                   # Project documentation

# ğŸ”„ Working Flow

Webcam Capture
Captures real-time video feed using OpenCV
Face Detection
Detects faces using Haar Cascade Classifier
Preprocessing
Converts image to grayscale
Resizes to 48Ã—48
Normalizes pixel values
Emotion Prediction
CNN model predicts the emotion from facial features
Music Recommendation
Corresponding playlist/song is played automatically
---

# ğŸ“š Libraries Used

cv2 (OpenCV) â€“ Face detection & video processing
tensorflow.keras â€“ Model building & prediction
numpy â€“ Numerical computations
imutils â€“ Simplified OpenCV operations
argparse â€“ Command-line argument handling
os â€“ File & directory operations
webbrowser â€“ Opens music links
time â€“ Delay handling
scikit-learn â€“ Model evaluation & preprocessing
matplotlib â€“ Data visualization
pandas â€“ Dataset handling
---

# âœ… Conclusion

FaceBeats successfully demonstrates how Artificial Intelligence, Machine Learning, and Computer Vision can work together to understand human emotions and respond in a meaningful way.
By detecting emotions in real time and recommending mood-matching music, FaceBeats enhances user experience and showcases the potential of emotionally intelligent systems. This project highlights how technology can become more personal, empathetic, and engaging through AI.

---
## Author 
Tannu Jha
